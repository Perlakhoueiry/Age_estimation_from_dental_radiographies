{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import Sequence\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "class CustomDataGenerator(Sequence):\n",
    "    \"\"\"Custom data generator for image and age data.\"\"\"\n",
    "\n",
    "    def __init__(self, image_paths, ages, batch_size, image_size, augment):\n",
    "        self.image_paths = image_paths\n",
    "        self.ages = ages\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        if self.augment:\n",
    "            self.datagen = ImageDataGenerator(\n",
    "                rotation_range=30,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get a batch of images and ages.\"\"\"\n",
    "        batch_image_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_ages = []\n",
    "\n",
    "        for i, image_path in enumerate(batch_image_paths):\n",
    "            image, age = self.load_and_preprocess_image(image_path)\n",
    "            augmented_image = self.apply_image_augmentation(image)\n",
    "            batch_images.append(augmented_image)\n",
    "            batch_ages.append(age)\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_ages = np.array(batch_ages)\n",
    "\n",
    "        return batch_images, batch_ages\n",
    "\n",
    "    def load_and_preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess an image from the given path.\"\"\"\n",
    "        npzfile = np.load(image_path)\n",
    "        image = npzfile['image']\n",
    "        Age = np.load(image_path)['Age']\n",
    "\n",
    "        image_resized = cv2.resize(image, self.image_size)\n",
    "        image_norm = (image_resized.astype('float32') - np.min(image_resized)) / (\n",
    "                    np.max(image_resized) - np.min(image_resized))\n",
    "\n",
    "        if len(image.shape) == 2:\n",
    "            image_tri = np.repeat(image_norm[:, :, np.newaxis], 3, axis=2)\n",
    "        else:\n",
    "            image_tri = image_norm\n",
    "\n",
    "        return image_tri, Age\n",
    "\n",
    "    def apply_image_augmentation(self, image):\n",
    "        \"\"\"Apply image augmentation on the given image.\"\"\"\n",
    "        if self.augment:\n",
    "            augmented_image = self.datagen.random_transform(image)\n",
    "        else:\n",
    "            augmented_image = image\n",
    "        return augmented_image\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths and parameters\n",
    "    train_path = r'E:/Papier/AIAGE/Base/reseau de neurones/save/train'\n",
    "    test_path = r'E:/Papier/AIAGE/Base/reseau de neurones/save/test'\n",
    "    batch_size = 32\n",
    "    image_size = (224, 224)\n",
    "    num_epochs = 10\n",
    "    k = 5\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Load image paths and ages\n",
    "    train_image_paths = [os.path.join(root, f) for root, dirs, files in os.walk(train_path) for f in files]\n",
    "    train_ages = [np.load(image_path)['Age'] for image_path in train_image_paths]\n",
    "    test_image_paths = [os.path.join(root, f) for root, dirs, files in os.walk(test_path) for f in files]\n",
    "    test_ages = [np.load(image_path)['Age'] for image_path in test_image_paths]\n",
    "\n",
    "    # Initialize the KFold object\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Initialize variables\n",
    "    cv_scores = []\n",
    "\n",
    "    # Loop through the folds in KFold and train the model\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(train_image_paths, train_ages)):\n",
    "        print(\"======================================\")\n",
    "        print(\"Iteration = \", i+1)\n",
    "\n",
    "        # Split the data into train and validation sets\n",
    "        X_train, X_val = np.array(train_image_paths)[train_index], np.array(train_image_paths)[test_index]\n",
    "        y_train, y_val = np.array(train_ages)[train_index], np.array(train_ages)[test_index]\n",
    "\n",
    "        # Create data generators\n",
    "        train_data_generator = CustomDataGenerator(X_train, y_train, batch_size, image_size, augment=True)\n",
    "        val_data_generator = CustomDataGenerator(X_val, y_val, batch_size, image_size, augment=False)\n",
    "        test_data_generator = CustomDataGenerator(test_image_paths, test_ages, batch_size, image_size, augment=False)\n",
    "\n",
    "        # Load the VGG19 model\n",
    "        base_model = VGG19(weights='//chu-lyon.fr/bureautique/TOUS_COMMUNS/BIOSTAT_COMMUN/etude60/6458 stage Perla El Khoueiry/analyse/AI_LA/Perla/reseaux-Age_binaire/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                       include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "        # Set layers in the model as trainable\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add layers on top of the VGG19 model\n",
    "        x = base_model.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        output = Dense(1, activation='linear')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "        # Compile the model with specified loss function, optimizer and metrics\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0001), metrics=['mean_absolute_error'])\n",
    "\n",
    "        # Print the summary of the model\n",
    "        model.summary()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(train_data_generator, epochs=num_epochs, validation_data=val_data_generator)\n",
    "\n",
    "        # Evaluate the model's performance\n",
    "        scores = model.evaluate(val_data_generator)\n",
    "\n",
    "        # Append score to cv_scores list\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "\n",
    "        # Print performance metrics and history\n",
    "        print(\"MSE: %.2f\" % (scores[0]))\n",
    "        print(\"MAE: %.2f\" % (scores[1]))\n",
    "\n",
    "    # Calculate the mean and standard deviation of the performance metrics\n",
    "    accuracy = np.mean(cv_scores)\n",
    "    std = np.std(cv_scores)\n",
    "#     print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (accuracy, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction \n",
    "y_pred_list=[]\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_list.append(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1979f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########learning curve#########\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.plot(history.history['mean_absolute_error'], label='training MAE')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation_MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss/MAE')\n",
    "plt.legend()\n",
    "plt.title('learning curves')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reel=test_ages\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_reel, y_pred, c='crimson')\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "p1 = max(max(y_pred), max(y_reel))\n",
    "p2 = min(min(y_pred), min(y_reel)) \n",
    "plt.plot([p1, p2], [p1, p2], 'b-') \n",
    "plt.xlabel('True Values', fontsize=15) \n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_ages,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
