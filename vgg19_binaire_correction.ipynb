{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bcbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 30/05/2023\n",
    "\n",
    "@author: Abdelmalek H\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import Sequence\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "class CustomDataGenerator(Sequence):\n",
    "    \"\"\"Custom data generator for image and age data.\"\"\"\n",
    "\n",
    "    def __init__(self, image_paths, ages, batch_size, image_size, augment):\n",
    "        self.image_paths = image_paths\n",
    "        self.ages = ages\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        if self.augment:\n",
    "            self.datagen = ImageDataGenerator(\n",
    "                rotation_range=30,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get a batch of images and ages.\"\"\"\n",
    "        batch_image_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_ages = []\n",
    "\n",
    "        for i, image_path in enumerate(batch_image_paths):\n",
    "            image, age = self.load_and_preprocess_image(image_path)\n",
    "            augmented_image = self.apply_image_augmentation(image)\n",
    "            batch_images.append(augmented_image)\n",
    "            batch_ages.append( batch_ages.append(1 if Age>18 else 0))\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_ages = np.array(batch_ages)\n",
    "\n",
    "        return batch_images, batch_ages\n",
    "\n",
    "    def load_and_preprocess_image(self, image_path):\n",
    "        \"\"\"Load and preprocess an image from the given path.\"\"\"\n",
    "        npzfile = np.load(image_path)\n",
    "        image = npzfile['image']\n",
    "        Age = np.load(image_path)['Age']\n",
    "\n",
    "        image_resized = cv2.resize(image, self.image_size)\n",
    "        image_norm = (image_resized.astype('float32') - np.min(image_resized)) / (\n",
    "                    np.max(image_resized) - np.min(image_resized))\n",
    "\n",
    "        if len(image.shape) == 2:\n",
    "            image_tri = np.repeat(image_norm[:, :, np.newaxis], 3, axis=2)\n",
    "        else:\n",
    "            image_tri = image_norm\n",
    "\n",
    "        return image_tri, Age\n",
    "\n",
    "    def apply_image_augmentation(self, image):\n",
    "        \"\"\"Apply image augmentation on the given image.\"\"\"\n",
    "        if self.augment:\n",
    "            augmented_image = self.datagen.random_transform(image)\n",
    "        else:\n",
    "            augmented_image = image\n",
    "        return augmented_image\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths and parameters\n",
    "    train_path = r'E:/Papier/AIAGE/Base/reseau de neurones/save/train'\n",
    "    test_path = r'E:/Papier/AIAGE/Base/reseau de neurones/save/test'\n",
    "    batch_size = 32\n",
    "    image_size = (224, 224)\n",
    "    num_epochs = 10\n",
    "    k = 5\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Load image paths and ages\n",
    "    train_image_paths = [os.path.join(root, f) for root, dirs, files in os.walk(train_path) for f in files]\n",
    "    train_ages = [np.load(image_path)['Age'] for image_path in train_image_paths]\n",
    "    train_ages_binary = [1 if np.load(image_path)['Age'] > 18 else 0 for image_path in train_image_paths]\n",
    "    test_image_paths = [os.path.join(root, f) for root, dirs, files in os.walk(test_path) for f in files]\n",
    "    test_ages = [np.load(image_path)['Age'] for image_path in test_image_paths]\n",
    "    test_ages_binary = [1 if np.load(image_path)['Age'] > 18 else 0 for image_path in test_image_paths]\n",
    "\n",
    "    # Initialize the KFold object\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Initialize variables\n",
    "    cv_scores = []\n",
    "\n",
    "    # Loop through the folds in KFold and train the model\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(train_image_paths, train_ages)):\n",
    "        print(\"======================================\")\n",
    "        print(\"Iteration = \", i+1)\n",
    "\n",
    "        # Split the data into train and validation sets\n",
    "        X_train, X_val = np.array(train_image_paths)[train_index], np.array(train_image_paths)[test_index]\n",
    "        y_train, y_val = np.array(train_ages)[train_index], np.array(train_ages)[test_index]\n",
    "\n",
    "        # Create data generators\n",
    "        train_data_generator = CustomDataGenerator(X_train, y_train, batch_size, image_size, augment=True)\n",
    "        val_data_generator = CustomDataGenerator(X_val, y_val, batch_size, image_size, augment=False)\n",
    "        test_data_generator = CustomDataGenerator(test_image_paths, test_ages, batch_size, image_size, augment=False)\n",
    "\n",
    "#         # Load the VGG19 model\n",
    "          \n",
    "#         base_model = VGG19(weights='//chu-lyon.fr/bureautique/TOUS_COMMUNS/BIOSTAT_COMMUN/etude60/6458 stage Perla El Khoueiry/analyse/AI_LA/Perla/reseaux-Age_binaire/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "#                        include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#         # Set layers in the model as trainable\n",
    "#         for layer in base_model.layers:\n",
    "#             layer.trainable = False\n",
    "\n",
    "#         # Add layers on top of the VGG19 model\n",
    "#         x = base_model.output\n",
    "#         x = Flatten()(x)\n",
    "#         x = Dense(256, activation='relu')(x)\n",
    "#         x = Dense(128, activation='relu')(x)\n",
    "#         output = Dense(1, activation='linear')(x)\n",
    "#         model = Model(inputs=base_model.input, outputs=output)\n",
    "        pretrained_model = load_model('//chu-lyon.fr/bureautique/TOUS_COMMUNS/BIOSTAT_COMMUN/etude60/6458 stage Perla El Khoueiry/analyse/AI_LA/Perla/model_sauvegarder/VGG19_continue.h5')\n",
    "        for layer in pretrained_model.layers:\n",
    "            layer.trainable = False\n",
    "#     Get the output of the previous layer\n",
    "        previous_output = pretrained_model.layers[-2].output\n",
    "\n",
    "   # Add a new dense layer with the desired number of units or classes \n",
    "        new_output = Dense(1, activation='sigmoid')(previous_output)\n",
    "\n",
    "   # Create the new model with the updated last layer \n",
    "        model = Model(inputs=pretrained_model.input, outputs=new_output)\n",
    "\n",
    "        # Compile the model with specified loss function, optimizer and metrics\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['precision'])\n",
    "\n",
    "        # Print the summary of the model\n",
    "        model.summary()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(train_data_generator, epochs=num_epochs, validation_data=val_data_generator)\n",
    "\n",
    "        # Evaluate the model's performance\n",
    "        scores = model.evaluate(test_data_generator)\n",
    "\n",
    "        # Append score to cv_scores list\n",
    "        cv_scores.append(scores[1] * 100)\n",
    "\n",
    "        # Print performance metrics and history\n",
    "        print(\"cross_entropy: %.2f\" % (scores[0]))\n",
    "        print(\"precision: %.2f\" % (scores[1]))\n",
    "\n",
    "    # Calculate the mean and standard deviation of the performance metrics\n",
    "    accuracy = np.mean(cv_scores)\n",
    "    std = np.std(cv_scores)\n",
    "    print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (accuracy, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
